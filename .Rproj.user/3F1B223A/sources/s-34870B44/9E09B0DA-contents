---
title: "News-popularity"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(readr)
library(purrr)
library(tidyr)
library(ggplot2)
library(caret)
library(data.table)
library(modelsummary)
library(kableExtra)
# 
# library(xtable)
# library(gridExtra)
# library(ggthemes)
# library(lattice)
# library(glmnet)
# library(rattle)
# library(Hmisc)
# library(modelsummary)
# library(data.table)
# library(data.tree)
# library(DiagrammeR)
library(gbm)
# library(xgboost)
library(pROC)
library(ROCR)
library(skimr)
library(h2o)
library(bit64)
# library(rpart)
# library(rpart.plot)



my_seed <- 20210410
```


# Intro

This is a report for the binary classification competition for the course Data Science 2: Machine Learning Tools, at CEU in the Spring semester of 2020/21.

In this competition, I try to predict which articles are shared the most on social media. The data comes from the website mashable.com from the beginning of 2015. The dataset used in the competition is from the UCI repository.



# EDA


Train and test datasets come from Data section of the competition.

This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal is to predict if the article is among the most popular ones based on sharing in social networks (coded by the variable "is_popular").

```{r, message=FALSE, echo=FALSE}
train_raw <- read_csv("data/train.csv")
test_raw <- read_csv("data/test.csv")
```

Train dataset contains 27752 observations and 60 variables. 

Test dataset contains 11892 observations and 59 variables. 


```{r}
datasummary_skim(train_raw) 

# %>% 
#     kable("html", caption = 'Summary stats') %>%
#   kable_styling(position = "center") %>% 
#   scroll_box(width = "100%", height = "300px")

# skimr::skim(train_raw)
```




Training dataset contains 60 columns, all numeric. None of them contains missing values. 

Even though we have a lot of columns, some of them are actually dummy variables. For example, 7 variables that starts with week_ (r.g. weekday_is_monday) shows whether the article was published on that day (Monday). is_weekend is also dummy variable that contains only values of 1 and 0 that shows whether the article was published on the weekend. 6 other dummy variables that starts with data_ (e.g. data_channel_is_lifestyle) shows the channel of the news (data channel 'Lifestyle'). 


```{r}
table(train_raw$is_popular)
```

Popular news are less than not popular news: there are 5466 popular news and 22286 not popular news. 


```{r}
table(train_raw$is_weekend)
```
3638 news were published at the weekend while 24114 news were published on weekdays. 


```{r}
ggplot(data=train_raw, aes(train_raw$is_popular)) +
  geom_boxplot()

# boxplot(train_raw$is_popular)

# boxplot(train_raw$is_weekend)

```


```{r}
table(train_raw$is_weekend)
```

Few articles published in weekend. 



```{r}

train_raw %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram()
```


# Data cleaning

The following variables are dummy variables: 

- 6 variables that start with data_

- 7 variables that start with week_

- is_weekend variable

I convert them from numeric into factor variables. 

Also, our target variable is *is_popular* variable. I also convert it into factor variable and give proper labels (yes, no) instead of 1 and 0.  

Now we have 15 factor and 45 numeric variables. 

```{r}
cols <- c("is_weekend", 
          colnames(train_raw[ , grepl( "weekday" , names( train_raw ) ) ]),
          colnames(train_raw[ , grepl( "data" , names( train_raw ) ) ]))
train_raw[,cols] <- lapply(train_raw[, cols], factor)

# Error: At least one of the class levels is not a valid R variable name; This will cause errors when class probabilities are generated because the variables names will be converted to  X0, X1 . Please use factor levels that can be used as valid R variable names  (see ?make.names for help).

train_raw <- 
  train_raw %>% mutate(
    is_popular = factor(is_popular, levels = list(1,0), labels = c('yes', 'no'))) %>% as.data.frame()


test_raw[,cols] <- lapply(test_raw[, cols], factor)

```



# Model


Let's start building models using the train data. 


## 1. Linear model 

Linear Probability Model produces values less than 0 or more than 1. But Logit model regularizes this process and gives results of 1 and 0 only. Therefore, I decided to use Logit for Linear Model. 

I used 5 fold cross-validation and set class probability for training control.  

```{r, warning=FALSE, echo=FALSE}

train_control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = TRUE
)
```

### Parameter tuning

Since we have a lot of columns, we need regularization technique. I used Logit LASSO and tried to identify best lambda and alpha values. 

```{r, warning=FALSE, message=FALSE}

# Logit lasso -----------------------------------------------------------

lambda <- 10^seq(-1, -4, length = 10)
grid <- expand.grid("alpha" = 1, lambda = lambda)

set.seed(my_seed)
logit_lasso_model <- train(
    is_popular ~ .,
    data = train_raw,
    method = "glmnet",
    preProcess = c("center", "scale"),
    family = "binomial",
    trControl = train_control,
    tuneGrid = grid,
    na.action=na.exclude
  )

tuned_logit_lasso_model <- logit_lasso_model$finalModel
# best_lambda <- logit_lasso_model$bestTune$lambda
logit_lasso_model$bestTune
```

Best lambda was 0.0004641589 and best alpha was 1. 

```{r}
# logit_lasso_model
cv_roc_folds <- logit_lasso_model$resample[,c("Resample", "ROC")]

logit_lasso_model$results[order(logit_lasso_model$results$ROC, decreasing = TRUE),][1,"ROC"]
```
ROC of Logit LASSO model is 0.6937. 

### Evaluation

Now it's time to make predictions on the test data. We saved predicted probabilities as 'score' variable. Then we make a dataframe with 'score' and 'article_id' columns. This dataframe contains our predictions. 

```{r}

test_raw[, 'score'] <- predict(logit_lasso_model, newdata = test_raw, type = "prob") %>%
  as.data.frame() %>% 
  select(yes)

to_submit <- test_raw[, c("article_id", "score")]

write.csv(to_submit, "submit_news_2.csv", row.names=FALSE)
```

I turned dataframe into CSV and submitted to Kaggle. The AUC of Logit lasso in Kaggle was 0.68890. 




```{r}
cv_fold <- logit_lasso_model$pred %>% 
  filter(Resample == "Fold1")
roc_obj <- roc(cv_fold$obs, cv_fold$yes)
roc_obj$auc
```
Area under the curve is 0.6758. 



## 2. Random Forest 

In most cases Random Forest captures non-linear relationships better than Linear Models.

### Parameter tuning 

Random Forest has several tuning parameters. For number of variables, I took the square root of the total number of variables, which would be 7 (approx. square root of 60) so I tried 7, 8, and 9. For the split rule, I took gini. I also took combination of 5 and 10 for the minimum node size.



```{r rf_tune, echo = FALSE, message=FALSE, warning=FALSE}
# do 5-fold CV
train_control <- trainControl(method = "cv",
                              number = 5,
                              classProbs = TRUE,
                              summaryFunction = twoClassSummary,
                              savePredictions = TRUE,
                              verboseIter = FALSE)

set.seed(my_seed)
# set tuning
tune_grid <- expand.grid(
  .mtry = c(7,8,9),
  .splitrule = c("gini"),
  .min.node.size = c(5, 10)
)

rf_model_1 <- train(
  is_popular ~ ., 
  data = train_raw,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)

head(rf_model_1$results[order(rf_model_1$results$ROC, decreasing = TRUE),], 1)
```

Tuning shows 7 as a number of variable and 10 as minimum node size gives best result. ROC is 0.7089616. 

### Evaluation

We predict probability in test set using Random Forest model this time. Dataframe that contains our predictions is turned into CSV and submitted to Kaggle. 

```{r}

# summary(rf_model_1)

test_raw[, 'score'] <- predict(rf_model_1, newdata = test_raw, type = "prob") %>%
  as.data.frame() %>% 
  select(yes)

to_submit <- test_raw[, c("article_id", "score")]

write.csv(to_submit, "submit_news_1.csv", row.names=FALSE)

```

Kaggle gives 0.71139 AUC for Random Forest prediction. 


## 3. Gradient Boosting 

Like random forests, gradient boosting is a set of decision trees. The two main differences are:

How trees are built: random forests builds each tree independently while gradient boosting builds one tree at a time. This additive model (ensemble) works in a forward stage-wise manner, introducing a weak learner to improve the shortcomings of existing weak learners.

Combining results: random forests combine results at the end of the process (by averaging or "majority rules") while gradient boosting combines results along the way.
If we carefully tune parameters, gradient boosting can result in better performance than random forests.


### Parameter tuning 

These are tuning parameters for the Gradient Boosting Machine: complexity of tree, number of trees, learning rate (how quickly the algorithm adapts), minimum samples. 
I took combination of 1, 5, and 10 for the complexity of the tree. For the number of trees, I experimented starting from 200 to 500 (stepping by 50). I decided to play around 10 values from 0.01 to 0.3 for the learning rate (shrinkage). 1 and 5 were investigated for the the minimum number of training set samples in a node to commence splitting. 

The final values used for the model were n.trees = 500, interaction.depth =
 1, shrinkage = 0.07444444 and n.minobsinnode = 5.
 
The Accuracy for the GBM is 0.8278804.

```{r gbm_tune, echo = FALSE, message=FALSE, warning=FALSE}

train_control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  savePredictions = TRUE
)

gbm_grid <-  expand.grid(interaction.depth = c(1, 5, 10), 
                         n.trees = (4:10)*50, 
                         shrinkage = seq(0.01,0.3,length=10), 
                         n.minobsinnode = c(1, 5))


set.seed(my_seed)

gbm_model <- train(
    is_popular ~ .,
    data = train_raw,
    method = "gbm",
    trControl = train_control,
    verbose = FALSE,
    tuneGrid = gbm_grid)

# gbm_model

gbm_model$results[order(gbm_model$results$Accuracy, decreasing = TRUE),][1,]

```


### Evaluation

```{r}
test_raw[, 'score'] <- predict(gbm_model, newdata = test_raw, type = "prob") %>%
  as.data.frame() %>% 
  select(yes)

to_submit <- test_raw[, c("article_id", "score")]

write.csv(to_submit, "submit_news_3.csv", row.names=FALSE)
```

0.70643 


## 4. Neural Network 

prediction after parameter tuning => layers.

size = number of nodes in the hidden layer
decay = It's regularization to avoid over-fitting.

decay: parameter for weight decay. Default 0.




```{r, warning=FALSE}
tune_grid_nnet <- expand.grid(
  size = c(3, 5, 7, 10, 15),
  decay = c(0.1, 0.5, 1, 1.5, 2, 2.5, 5)
)

set.seed(my_seed)

nnet_model <- train(
  is_popular ~ .,
  method = "nnet",
  data = train_raw,
  trControl = train_control,
  tuneGrid = tune_grid_nnet,
  preProcess = c("center", "scale", "pca"),
  metric = "ROC",
  trace = FALSE
)

```


### Evaluation

```{r}
test_raw[, 'score'] <- predict(nnet_model, newdata = test_raw, type = "prob") %>%
  as.data.frame() %>% 
  select(yes)

to_submit <- test_raw[, c("article_id", "score")]

write.csv(to_submit, "submit_news_4.csv", row.names=FALSE)
```

Kaggle 0.69465





# For extra points, build a stacked model and submit the prediction to Kaggle, explain how it works, and evaluate its results in the Rmd document.

```{r}
# Initialize H2O
h2o.no_progress() 
h2o.init(max_mem_size = "8g")
# Create H2O datasets
data_train <- as.h2o(train_raw)
data_test <- as.h2o(test_raw)
# Set the target variable
y <- "is_popular"
X <- setdiff(names(data_train), y)
```

```{r}
four_models <- list(logit_lasso_model, rf_model_1, gbm_model, nnet_model)

```



### f. Create a stacked ensemble model from the base learners.

```{r stack, echo = FALSE, message=FALSE, warning=FALSE, results='hide'}

ensemble_model <- h2o.stackedEnsemble(
  X, y,
  training_frame = data_train,
  base_models = four_models,
  seed = my_seed,
  keep_levelone_frame = TRUE
)

```

```



